{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haseeb/miniconda3/envs/English2Hinglish_tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from unicodedata import normalize\n",
    "import string\n",
    "import keras\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import warnings\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Input, Bidirectional, LSTM, Dense, Concatenate\n",
    "from tensorflow.keras.initializers import Constant\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from datasets import load_dataset\n",
    "import collections\n",
    "import json\n",
    "from google.transliteration import transliterate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "#using this implementation of attention\n",
    "#https://github.com/thushv89/attention_keras/blob/master/src/layers/attention.py\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def _init_(self, **kwargs):\n",
    "        super(AttentionLayer, self)._init_(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model(\"Seq2seq_transformer_model.h5\",custom_objects={\"AttentionLayer\": AttentionLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder inference model\n",
    "encoder_inf_inputs = loaded_model.input[0]  # input_1\n",
    "encoder_inf_output2,encoder_inf_state_h2, encoder_inf_state_c2 = loaded_model.layers[5].output\n",
    "encoder_inf_model = Model(inputs=encoder_inf_inputs,outputs=[encoder_inf_output2,encoder_inf_state_h2, encoder_inf_state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder inference model\n",
    "latent_dim = 300\n",
    "decoder_inf_inputs = loaded_model.input[1]\n",
    "\n",
    "encoder_out_temp = Input(shape=(40,latent_dim), name = \"encoder_input\")\n",
    "encoder_state_input_h = Input(shape=(latent_dim,), name = \"encoder_hidden_state\")\n",
    "encoder_state_input_c = Input(shape=(latent_dim,), name = \"encoder_cell_state\")\n",
    "\n",
    "decoder_embed_layer = loaded_model.layers[4]\n",
    "decoder_embeddings = decoder_embed_layer(decoder_inf_inputs)\n",
    "\n",
    "decoder_inf_lstm = loaded_model.layers[6]\n",
    "decoder_inf_outputs, decoder_state_h2, decoder_state_c2 = decoder_inf_lstm(decoder_embeddings, initial_state=[encoder_state_input_h, encoder_state_input_c])\n",
    "\n",
    "# attention_inf_layer = loaded_model.layers[7], this is the attention model from the model but \n",
    "decoder_attention = loaded_model.layers[7]\n",
    "attn_out_inf,_=decoder_attention([encoder_out_temp, decoder_inf_outputs])\n",
    "# concat\n",
    "decoder_inf_concat=tf.keras.layers.Concatenate()([decoder_inf_outputs, attn_out_inf])\n",
    "# time_distributed\n",
    "time = loaded_model.layers[9]\n",
    "decoder_outputs2 = time(decoder_inf_concat)\n",
    "\n",
    "decoder_model = Model(\n",
    "inputs = [decoder_inf_inputs] + [encoder_out_temp,encoder_state_input_h, encoder_state_input_c],\n",
    "outputs = [decoder_outputs2] + [decoder_state_h2, decoder_state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"assets/en_dict.json\", \"r\") as json_file:\n",
    "    english_word_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"assets/hing_rev_dict.json\", \"r\") as json_file:\n",
    "    hinglish_reversed_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(text):\n",
    "    # pad the text\n",
    "    max_length = 40\n",
    "    \n",
    "    tokenized = word_tokenize(text)[:max_length]\n",
    "    padded_text = tokenized + (max_length - len(tokenized)) * [\"<padding>\"]\n",
    "\n",
    "    #initialising the training data\n",
    "    encoder_input_data = np.zeros(\n",
    "        (1, max_length),\n",
    "        dtype='float32')\n",
    "    \n",
    "    for t, char in enumerate(padded_text):\n",
    "        try:\n",
    "            #use unk if we cant find the word in the dictionary\n",
    "            encoder_input_data[0, t] = english_word_dict.get(\n",
    "                char, english_word_dict[\"<unk>\"])\n",
    "        except:\n",
    "            print(char)\n",
    "    \n",
    "    return encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"definitely share you feedback in the comment section\"\n",
    "sentence2 = \"so even if its a big video, I will clearly mention all the products\"\n",
    "sentence3 = \"I was waiting for my bag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test = prepare_text(sentence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 20:02:04.879107: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 449ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "kya\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "aaj\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "raat\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "baarish\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hogi\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "#encoding incoming data\n",
    "e_out, e_h, e_c=encoder_inf_model.predict(encoded_test)\n",
    "#creating target sequence\n",
    "target_seq = np.zeros((1,1))\n",
    "#inputing start token\n",
    "target_seq[0, 0] = english_word_dict['<s>']\n",
    "stop_condition = False\n",
    "decoded_sentence = ''\n",
    "#looping until stop token is predicted or \n",
    "while not stop_condition:\n",
    "    output_tokens, h, c = decoder_model.predict(\n",
    "        [target_seq] + [e_out, e_h, e_c])\n",
    "    #want to get index with highest probability\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    #find word at that index\n",
    "    sampled_char = hinglish_reversed_dict[f\"{sampled_token_index}\"]\n",
    "    print(sampled_char)\n",
    "    #add to sentence\n",
    "    decoded_sentence += ' '+sampled_char\n",
    "    if (sampled_char == \"</s>\" or len(word_tokenize(decoded_sentence)) > 52):\n",
    "        stop_condition = True\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = sampled_token_index\n",
    "    #update hidden + cell states\n",
    "    e_h, e_c = h, c\n",
    "# remove the \n",
    "decoded_sentence = decoded_sentence[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transliterate(decoded_sentence):\n",
    "    from google.transliteration import transliterate_text\n",
    "    \n",
    "    # Get english dictionary reference\n",
    "    with open('assets/3kpop.txt', 'r') as file:\n",
    "        file_content = file.read()\n",
    "    wordlist = file_content.split()\n",
    "    \n",
    "    # transliterate\n",
    "    hindi = transliterate_text(decoded_sentence, lang_code='hi')\n",
    "    \n",
    "    # check if words are english; if they are, replace them\n",
    "    hinglish_final = hindi.split()\n",
    "    for index,word in enumerate(decoded_sentence.split()):\n",
    "        if word in wordlist:\n",
    "            hinglish_final[index] = word\n",
    "    #' '.join(hinglish_final)\n",
    "\n",
    "    return ' '.join(hinglish_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " kya aaj raat baarish hogi  \n",
      " क्या आज रात बारिश होगी\n"
     ]
    }
   ],
   "source": [
    "print(decoded_sentence,'\\n', transliterate(decoded_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "English2Hinglish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
